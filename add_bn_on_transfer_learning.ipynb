{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    " \n",
    " \n",
    "seed = 42\n",
    "epochs = 1\n",
    "records_per_class = 100\n",
    " \n",
    "# We take only 2 classes from CIFAR10 and a very small sample to intentionally overfit the model.\n",
    "# We will also use the same data for train/test and expect that Keras will give the same accuracy.\n",
    "(x, y), _ = cifar10.load_data()\n",
    " \n",
    "def filter_resize(category):\n",
    "   # We do the preprocessing here instead in the Generator to get around a bug on Keras 2.1.5.\n",
    "   return [preprocess_input(imresize(img, (224,224)).astype('float')) for img in x[y.flatten()==category][:records_per_class]]\n",
    " \n",
    "x = np.stack(filter_resize(3)+filter_resize(5))\n",
    "records_per_class = x.shape[0] // 2\n",
    "y = np.array([[1,0]]*records_per_class + [[0,1]]*records_per_class)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 745ms/step - loss: 0.7640 - accuracy: 0.5700 - val_loss: 0.2919 - val_accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# We will use a pre-trained model and finetune the top layers.\n",
    "np.random.seed(seed)\n",
    "def mymodel():\n",
    "    with K.learning_phase_scope(0):\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    # base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    c = keras.layers.Conv2D(64, (3, 3), padding='same')(base_model.output)\n",
    "    \n",
    "#     b = keras.layers.BatchNormalization(momentum=0.9)(c, training=True) # this way save state in h5 file\n",
    "#     with K.learning_phase_scope(1): # this way don't save state in h5 file\n",
    "#         b = keras.layers.BatchNormalization(momentum=0.99)(c)\n",
    "    b = keras.layers.BatchNormalization(momentum=0.99)(c)\n",
    "    r = keras.layers.ReLU()(b)\n",
    "    l = Flatten()(r)\n",
    "    # l = Flatten()(base_model.output)\n",
    "    predictions = Dense(2, activation='softmax')(l)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in model.layers[:140]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[140:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = mymodel()\n",
    "model.fit_generator(ImageDataGenerator().flow(x, y, seed=42), epochs=epochs, validation_data=ImageDataGenerator().flow(x, y, seed=42))\n",
    " \n",
    "# Store the model on disk\n",
    "model.save('tmp.h5')\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9999163 , 0.99998325, 0.9999877 , 0.99989146, 0.99992657,\n",
       "        0.99976426, 1.0000074 , 1.0000465 , 0.99999577, 0.99994373,\n",
       "        1.0000684 , 0.9998759 , 1.0001304 , 1.0000405 , 1.0000027 ,\n",
       "        1.0000796 , 0.9998667 , 0.9999276 , 1.0000191 , 0.9999217 ,\n",
       "        0.9999243 , 0.99997   , 0.99995923, 1.0001112 , 1.000051  ,\n",
       "        1.0000095 , 0.99995774, 1.0001501 , 0.99995637, 0.9999779 ,\n",
       "        0.9999396 , 1.000062  , 1.0000038 , 0.9998946 , 0.99996436,\n",
       "        0.9999806 , 1.0000055 , 0.99988204, 0.999955  , 1.0000309 ,\n",
       "        1.0001107 , 1.0000203 , 1.0001026 , 1.0000283 , 1.0000458 ,\n",
       "        1.0000329 , 0.99991006, 0.99997276, 0.99992627, 1.0000035 ,\n",
       "        1.0000618 , 0.9998756 , 0.99981934, 0.99999666, 1.0000732 ,\n",
       "        0.99993163, 0.99993765, 0.9999517 , 0.9999914 , 0.9999175 ,\n",
       "        0.9999729 , 0.99992675, 1.0000046 , 0.9997653 ], dtype=float32),\n",
       " array([-3.88650333e-05,  6.52829840e-05, -4.68558901e-05, -6.33832460e-05,\n",
       "        -2.05347988e-05, -1.41212469e-04,  1.28227202e-05,  5.44050090e-05,\n",
       "        -3.33700154e-05, -8.06784519e-05,  6.51865485e-05, -2.96398666e-05,\n",
       "         1.17980766e-04, -1.72656507e-06, -3.39684739e-05,  1.30329921e-04,\n",
       "        -1.40092568e-04, -6.77433491e-05,  2.21042410e-05, -5.15570355e-05,\n",
       "        -2.00965133e-05,  9.40698919e-06, -3.37653619e-05,  6.93700567e-05,\n",
       "         5.59324835e-05,  7.20957614e-05, -3.47618334e-05,  8.48557102e-05,\n",
       "         2.73133151e-06, -4.18345844e-05, -1.12591224e-05,  2.18566020e-05,\n",
       "         3.71094793e-05, -1.09421999e-04, -4.83536132e-05,  1.07932613e-06,\n",
       "        -6.80915764e-05, -1.78714363e-05, -9.06369241e-05,  4.09867207e-05,\n",
       "         1.12015754e-04,  8.79773143e-05,  3.84244231e-05,  3.19409592e-05,\n",
       "         3.91641079e-05,  2.75633702e-05, -8.37399857e-05, -2.36048490e-05,\n",
       "        -2.15376494e-05, -3.82269536e-05,  7.09484011e-05, -6.55273616e-05,\n",
       "        -1.31800058e-04, -4.38675579e-06,  7.64412180e-05, -4.98920053e-05,\n",
       "        -6.89028893e-05, -9.55109717e-05, -6.86602871e-05,  9.13580880e-06,\n",
       "        -3.52555471e-05, -7.77069436e-05, -1.82959138e-05, -1.78539762e-04],\n",
       "       dtype=float32),\n",
       " array([-0.08475036,  0.05724409,  0.01845456, -0.03021971, -0.0207395 ,\n",
       "         0.0520262 ,  0.11057127, -0.03490756, -0.12330763,  0.07834272,\n",
       "         0.09092565, -0.04299593, -0.02330673,  0.0586383 , -0.06148091,\n",
       "         0.00842247,  0.07871343,  0.05317217, -0.00513533, -0.01999035,\n",
       "         0.02538066, -0.08002428,  0.01183848,  0.11382337,  0.05674319,\n",
       "        -0.08100681,  0.0137515 ,  0.01611091, -0.01688918, -0.12230705,\n",
       "        -0.10183585,  0.02846559,  0.02891756, -0.08136094, -0.06042756,\n",
       "        -0.07170333,  0.01385123, -0.02644662, -0.0299767 ,  0.10565566,\n",
       "        -0.05405052, -0.02071716,  0.10920091, -0.12219787, -0.09999194,\n",
       "        -0.11064106,  0.02938824, -0.11539741,  0.07812873,  0.0369719 ,\n",
       "         0.06955648, -0.06547357, -0.06552804,  0.11399302,  0.03368197,\n",
       "         0.05169866,  0.03855432,  0.03574032,  0.02878199, -0.08815974,\n",
       "         0.13106333,  0.00426893,  0.03672613, -0.09005226], dtype=float32),\n",
       " array([1.2465105, 1.2055502, 1.2373682, 1.2105266, 1.1916662, 1.2529557,\n",
       "        1.2624326, 1.2466894, 1.289947 , 1.2364017, 1.252083 , 1.2734565,\n",
       "        1.1914569, 1.2299635, 1.2354547, 1.2087678, 1.2233747, 1.2158414,\n",
       "        1.2662627, 1.2917303, 1.2438992, 1.2700218, 1.2516925, 1.2603008,\n",
       "        1.2169926, 1.2411333, 1.2179738, 1.2633228, 1.2540733, 1.2434415,\n",
       "        1.2572186, 1.2356391, 1.2164404, 1.3057482, 1.2740839, 1.2056358,\n",
       "        1.2122362, 1.2318339, 1.1892842, 1.3003705, 1.2873151, 1.1888486,\n",
       "        1.3329259, 1.3270171, 1.2613323, 1.3042253, 1.1837412, 1.2586716,\n",
       "        1.2871125, 1.2238157, 1.2073858, 1.2412809, 1.2148077, 1.2647946,\n",
       "        1.210207 , 1.1769587, 1.2192878, 1.2635169, 1.2547089, 1.2136092,\n",
       "        1.305087 , 1.2431563, 1.2027007, 1.2644802], dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING_PHASE 0,0\n",
      "[0.2918673705841814, 0.83]\n",
      "LEARNING_PHASE 0,1\n",
      "[0.34467991814017296, 0.875]\n",
      "LEARNING_PHASE 1,0\n",
      "[0.8779313734599522, 0.575]\n",
      "LEARNING_PHASE 1,1\n",
      "[0.7295647859573364, 0.59]\n",
      "DYNAMIC LEARNING_PHASE the same as the saved_h5_model\n",
      "[0.2918673705841814, 0.83]\n"
     ]
    }
   ],
   "source": [
    "def mymodel(t1, t2):\n",
    "    with K.learning_phase_scope(t1):\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    # base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    c = keras.layers.Conv2D(64, (3, 3), padding='same')(base_model.output)\n",
    "    b = keras.layers.BatchNormalization(momentum=0.9)(c, training=t2)\n",
    "#     with K.learning_phase_scope(t2):\n",
    "#         b = keras.layers.BatchNormalization(momentum=0.9)(c)\n",
    "    r = keras.layers.ReLU()(b)\n",
    "    l = Flatten()(r)\n",
    "    # l = Flatten()(base_model.output)\n",
    "    predictions = Dense(2, activation='softmax')(l)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in model.layers[:140]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[140:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# the new bn layer momentun 0.99 so large that moving_mean&&var can not learn well by small train_steps(epoch).\n",
    "print('LEARNING_PHASE 0,0')\n",
    "K.clear_session()\n",
    "model = mymodel(0,0)\n",
    "model.load_weights('tmp.h5')\n",
    "print(model.evaluate_generator(ImageDataGenerator().flow(x, y, seed=42)))\n",
    "\n",
    "# would get better result because using mean&&var(compute by mini-batch) from the distribution of new dataset.\n",
    "print('LEARNING_PHASE 0,1')\n",
    "K.clear_session()\n",
    "model = mymodel(0,1)\n",
    "model.load_weights('tmp.h5')\n",
    "print(model.evaluate_generator(ImageDataGenerator().flow(x, y, seed=42)))\n",
    "\n",
    "print('LEARNING_PHASE 1,0') \n",
    "K.clear_session()\n",
    "model = mymodel(1,0)\n",
    "model.load_weights('tmp.h5')\n",
    "print(model.evaluate_generator(ImageDataGenerator().flow(x, y, seed=42)))\n",
    "\n",
    "print('LEARNING_PHASE 1,1')\n",
    "K.clear_session()\n",
    "model = mymodel(1,1)\n",
    "model.load_weights('tmp.h5')\n",
    "print(model.evaluate_generator(ImageDataGenerator().flow(x, y, seed=42)))\n",
    "\n",
    "print('DYNAMIC LEARNING_PHASE the same as the saved_h5_model')\n",
    "K.clear_session()\n",
    "model = load_model('tmp.h5')\n",
    "# This accuracy should match exactly the one of the validation set on the last iteration.\n",
    "print(model.evaluate_generator(ImageDataGenerator().flow(x, y, seed=42)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
